{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Demo for Machine epsilon and floating point arithmetic\n",
    "The following is an algorithm to find the approximate location of machine epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_h(x,h):\n",
    "    ''' The objective here is to see how x affects h.\n",
    "    1. We add x to h. In computer x+h is approximated using floating point arithmetic.\n",
    "    2. Then we subtract x'''\n",
    "    return ((x+h) - x)\n",
    "\n",
    "exponents = np.arange(-10,-17,-0.01)\n",
    "h_actual = 10.0**exponents\n",
    "x=1\n",
    "h_evaluated = evaluate_h(x,h_actual)\n",
    "plt.loglog(h_actual, h_evaluated, label= f\"x ={x}\")\n",
    "plt.ylim(1e-17,1e-10)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"h\")\n",
    "plt.ylabel(\"(x+h)-x\")\n",
    "plt.title(\"Demonstration of Machine epsilon\")\n",
    "plt.grid(linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "From the above clearly the machine epsilon is somewhere near $10^{-16}$. Now let us try to find the exact location of machine epsilon. \n",
    "For this let us use the definition of machine epsilon.\n",
    "Machine epsilon is defined as the smallest step size to take to obtain the number that is greater than 1 and is closest to 1 which is representable in a computer. But before this let us view the error plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponents = np.arange(1,-20,-1)\n",
    "h_actual = 10.0**(-15)*np.linspace(0.01,10,1000)\n",
    "x=1\n",
    "h_evaluated = evaluate_h(x,h_actual)\n",
    "error = np.abs(h_evaluated - h_actual)\n",
    "plt.loglog(h_actual, error, c=\"b\", label= f\"abs error for x ={x}\")\n",
    "plt.loglog(h_actual, h_actual, \"r--\",label= f\"h_actual\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"h\")\n",
    "plt.ylabel(\"abs error = |[(x+h)-x]-h|\")\n",
    "plt.title(\"Demonstration of Machine epsilon\")\n",
    "plt.grid(linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Let us examine the above plot.\n",
    "1. The y axis shows the h_evaluated - h_actual. Till $\\approx 10^{-16}$ we see the h_actual curve coinicides with abs error. This is because  $$abs(h_{evaluated} - h_{actual}) = |[(1+h) - 1] - h| = |[0] - h| = h$$ \n",
    "2. The h corresponding to the first valley is the machine epsilon. Hence the machine epsion from the plot is $\\approx 2*10^{-16}$ (The actual value is $2^{-52}$). Infact each valley is the number that is accurately resentable on the computer.\n",
    "3. Why is there a deviation of the blue line from the red line above even before machine epsilon? And what is its value?\n",
    "    - This is because of rounding off.\n",
    "    - Its value is exactly $\\frac{\\varepsilon}{2}$.\n",
    "    To understand more about it read about rounding off. Its beautiful.\n",
    "\n",
    "To appreciate point number 2 more in the above statements, let us do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_epsilon = np.finfo(float).eps\n",
    "h = np.linspace(0,5,1000) * machine_epsilon\n",
    "multiples_of_machine_epsilon = np.arange(0,5)*machine_epsilon\n",
    "x = 1\n",
    "h_evaluated = ((x + h) - x)\n",
    "plt.plot(h, h_evaluated, \"b-\", label=f\"(x+h)-x\")\n",
    "plt.plot(h, h_evaluated-h, label=f\"(x+h)-x - h\", linestyle=\"--\")\n",
    "plt.plot(h, h, \"r--\",label=f\"h\")\n",
    "for line in multiples_of_machine_epsilon:\n",
    "    plt.axvline(x=line, color=\"g\", linestyle=\"-.\", linewidth=0.5)\n",
    "    plt.axhline(y=0, color=\"k\", linestyle=\"-.\", linewidth=0.5)\n",
    "plt.xlabel(\"h\")\n",
    "\n",
    "plt.title(\"Demonstration of Machine epsilon\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "From the above plot we see where the rounding is happening and the points where the error is 0. As this error gets to 0,earlier in the loglog plot we observed valleys. And since loglog plot cannot handle log(0) properly we have valleys of varying depths. The vertical green lines indicate multiples of machine epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_epsilon = np.finfo(float).eps\n",
    "h = np.linspace(0,11,1000) * machine_epsilon\n",
    "multiples_of_machine_epsilon = np.arange(0,11)*machine_epsilon\n",
    "\n",
    "x = 1\n",
    "h_evaluated = ((x + h) - x)\n",
    "plt.plot(h, h_evaluated, \"b-\", linewidth=2, label=f\"x=1\")\n",
    "\n",
    "x = 2\n",
    "h_evaluated = ((x + h) - x)\n",
    "plt.plot(h, h_evaluated, \"k-\", linewidth=1, label=f\"x=2\")\n",
    "plt.plot(h, h, \"r--\",label=f\"h\")\n",
    "\n",
    "x = 4\n",
    "h_evaluated = ((x + h) - x)\n",
    "plt.plot(h, h_evaluated, \"y-\",  linewidth=2, label=f\"x=4\", alpha=0.5)\n",
    "for line in multiples_of_machine_epsilon:\n",
    "    plt.axvline(x=line, color=\"g\", linestyle=\"-.\", linewidth=0.5)\n",
    "\n",
    "plt.xlabel(\"h\")\n",
    "plt.title(\"Demonstration of Machine epsilon\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "In the above plot we are demonstrating te following:\n",
    "1. The seperation between numbers represented on the computer accurately is $\\varepsilon$ when the number is between 1 and 2.\n",
    "2. It is doubled ($2*\\varepsilon$) when the number is between 2 and 4.\n",
    "3. It becomes $2^2 * \\varepsilon$ when the number is between 4 and 8."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ky",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
